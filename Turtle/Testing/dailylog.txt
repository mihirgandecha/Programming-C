1. Framework to tell you what is passing and failing - testing framework traps your code
2. Call another function instead of EXIT - or flag set in testing mode

Loopup Unit Testing
Redefine your own version of EXIT

15th Jan:

Asked about:
- testing with Neil - explained to use bash script and store num in $V, and if -eq 0 (EXIT_FAILURE)..then do X, else... do Y.

- Whitebox vs Blackbox testing: sqrt(double num)

	-Whitebox testing internal structure
		-ie tester knows exact implementation of SQRT func, ie algorithms used, i/o handling..
		-Tester creates cases to check if +ve num, 0, -ve num, edge cases
		-GOAL: Ensure function implemented correctly+handles inputs as expected
		-Turtle Eg: Test if calloc worked! Assert testing?		
		
	-Blackbox testing: No knowledge of internal works
		-They only know function calculated sqrt
		-test sqrt(4)==2
		-Given only functionality, what can we test for?
		-Turtle eg: Running TTL's through Parser. Maybe more assert testing?
	(Interpreter: if %success > say 80%)
		
1. For testing I first had to understand the difference between Whitebox vs Blackbox testing...(see above)
2. Next have to understand and evaluate what is the best way of representing these tests...
	ie Test Harness vs Test Framework
	Found that there is a lot of content on the difference between two in Software Engineering
	To evaluate - found I should understand needs of Turtle Parser/Interp:
		1. Complexity: If complex algorithms then more robust test harness should be used.
		2. Development Phase: 
		(EVAL FOR TEST FRAMEWORK): Test framework more beneficial in early stage of UNIT TESTING (using flags (off the shelf) to say where it failed rather than just crash program). Writing and executing tests for individual components.
		(EVAL FOR TEST HARNESS): If you are growing the program (which we are by copy/paste parser to interp) and components are tested together, test harness is more essential. Provides environment for testing independant components.
		
TO conclude:
    Best Practices: Often, the most robust approach is to use both. A test framework helps you ensure that each piece of your Turtle program works correctly in isolation. Meanwhile, a test harness lets you test how these pieces work together under different conditions.
    Continuous Testing Cycle: Use the test framework for regular unit tests as you develop. As features are integrated, use the test harness to ensure they work together seamlessly.
    

DEVELOPMENT PHASES::

	INITIAL (writing parser): Test Framework should be used as we are unit testing individual grammar components of parser. This allows immediate feedback on eg. Syntax grammar error found on ...testing edge cases...and error free before moving into Interpreter. 
	
	FURTHER DEVELOPMENT (integrating parser with interpreter): Test harness should be used as it helps test how well the parser integrates with the interpreter (ie testing the entire flow from parsing commands to executing them).
		eg testing sequence of commands (ie RIGHT 90 with FORWARD 5), handling runtime error, and overall performance (does this include (0/N?)
		
		
::Reflection::
My initial thoughts are I want to differenciate Whitebox vs Blackbox to make clearer. Starting out with parser I want to build test framework. Therefore When doing Blackbox testing I will pass the TTL files given (and write up more with where the parser could be caught out given grammar) and run it through the parser. I will be using unit testing, and so as I wrote a long list of assert test and found that when running test(), as there were EXIT_FAILURE lecturer explained bash script is more sensible. I will rectify by taking my unit tests that have EXIT_FAILURE and replace with bash script, such that  I use the method (store num in $V, and if -eq 0 (EXIT_FAILURE)..then do X, else... do Y). Then for whitebox my initial thoughts are that there are not many tests here, but we can check if Turtle initialised properly and maybe handling of recursion functions (or should this be in Blackbox?).  

When moving to interpreter as we are recommended to copy/paste I should find a way of parsing ttl instructions first such that they are error free, and figure out how to setup test harness. What should I be testing in interpreter? How can I differenciate by whitebox vs blackbox? 

Bug Reflection: Next time I should think solely about evaluating testing first. Thus I would be saving time as did so many assertions for parser. However greatful that I ran into problem now as it is widely spoken about in Software Engineering.




Methadology (rewrite):
Your methodology for testing the Turtle parser and interpreter seems well thought out. Let's refine it further by differentiating between white-box and black-box testing approaches for both the parser and the interpreter. We'll also consider how to transition from using a test framework to a test harness effectively.

----Phase 1: Parser Testing----

----(1)Black-Box Testing----
- Test with TTL Files: Pass various TTL files (both provided and custom-created) through the parser. These files should be designed to test different aspects of the grammar and potential edge cases.
- Unit Testing: using a flag to see if we are getting the correct output 


----(2)Black-Box Testing----
- **Internal Checks**: Focus on the internal logic of the parser. This includes how it handles recursion, memory allocation for structures, error handling, etc.
- **Assert Tests**: Use assert tests to validate the internal state after parsing operations. For example, checking if the parser correctly constructs a syntax tree or if it correctly identifies syntax errors.
- **Initialization Checks**: Test whether the Turtle structure is initialized properly, and if all components of the parser are in the correct state before and after parsing.

----Phase 2: Interp Testing----

- **Integration of Parser**: Since you're advised to copy-paste the parser into the interpreter, your existing parser tests (especially black-box tests) can be reused. Ensure that the parser component still functions correctly within the context of the interpreter. NEED TO CONSIDER IF WE ARE GIVEN .TTL FILES -> INTERP. THEN HOW CAN WE SAY IF NO ERROR IN PARSER -> INTERPRET!


NOW LEARN FROM PAST MISTAKES AND TAKE TIME TO LEARN HOW OTHERS HAVE TESTED WITH .PDF, .TXT, SCREEN FILES, IS THIS BLACK || WHITE BOX?


::REWRITE::

----(1)Black-Box Testing----
- **Functionality

Tests**: Focus on how the interpreter handles and executes the parsed commands. This includes testing whether the interpreter correctly executes a series of TTL instructions and produces the expected output or behavior.
- **Error Handling**: Test how the interpreter handles runtime errors or invalid commands. This can include feeding it commands that are syntactically correct but semantically incorrect, and seeing if it handles these gracefully.
- **User Scenarios**: Simulate real-world use cases

where TTL instructions are executed as they would be in practical scenarios. Check for correct execution, handling of edge cases, and overall system behavior.

#### White-Box Testing
- **Internal Logic**: Examine the internal workings of the interpreter, such as how it processes the output of the parser, manages state changes, and handles command execution.
- **Data Handling**: Test the handling of data within the interpreter, such as variable storage, scope management, and the handling of data types (if applicable).
- **Performance Checks**: Evaluate the efficiency of the interpreter. This might include checking how it performs under stress (e.g., with a large number of commands or complex nested instructions).

### Methodology for Setting Up Test Harness for Interpreter

1. **Simulate Full Environment**: Set up a test harness that simulates the full operating environment of the interpreter, including input/output handling


